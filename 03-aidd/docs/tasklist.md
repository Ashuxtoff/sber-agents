# План разработки бота

## Прогресс

| Итерация | Статус | Описание |
|----------|--------|----------|
| 0 - Настройка проекта | ✅ Готово | Инициализация окружения и зависимостей |
| 1 - Базовый бот | ✅ Готово | Эхо-бот для проверки работы Telegram API |
| 2 - Интеграция с LLM | ⏳ В процессе | Подключение OpenRouter и вызов модели |
| 3 - Ассистент с ролью | ⏸️ Ожидает | Добавление системного промпта |
| 4 - Обработка ошибок | ⏸️ Ожидает | Корректная обработка ошибок API |
| 5 - Документация | ⏸️ Ожидает | README с инструкциями запуска |

**Легенда:** ⏳ В процессе | ✅ Готово | ⏸️ Ожидает

---

## Итерация 0: Настройка проекта

**Цель:** Подготовить окружение для разработки

- [x] Создать `pyproject.toml` с зависимостями (aiogram, openai, python-dotenv)
- [x] Создать `.gitignore` (.env, __pycache__, .venv)
- [x] Создать `.env.example` с шаблоном переменных
- [x] Создать `Makefile` с командами (install, run)
- [x] Протестировать: `make install` создает окружение

**Критерий завершения:** Можно установить зависимости через `uv`

---

## Итерация 1: Базовый бот

**Цель:** Бот отвечает на сообщения

- [x] Создать структуру `bot.py` (импорты, конфигурация, инициализация)
- [x] Добавить хендлер на текст сообщения
- [x] Реализовать эхо-ответ (бот возвращает сообщение пользователя)
- [x] Добавить логирование через `print()` (старт, получение сообщения)
- [x] Протестировать: отправить сообщение в бот, получить эхо-ответ

**Критерий завершения:** Бот отвечает в Telegram и выводит логи в консоль

---

## Итерация 2: Интеграция с LLM

**Цель:** Бот отвечает через LLM вместо эхо

- [ ] Инициализировать OpenAI client с OpenRouter base_url
- [ ] Создать функцию вызова LLM
- [ ] Заменить эхо на вызов LLM
- [ ] Добавить логирование вызовов LLM
- [ ] Протестировать: бот отвечает через модель (без системного промпта)

**Критерий завершения:** Бот отправляет ответы через OpenRouter API

---

## Итерация 3: Ассистент с ролью

**Цель:** Бот ведет диалог с заданной ролью

- [ ] Определить системный промпт с ролью ассистента
- [ ] Добавить системный промпт в вызов LLM
- [ ] Протестировать: бот отвечает согласно роли
- [ ] Проверить: разные вопросы → разные ответы

**Критерий завершения:** Бот ведет диалог в заданной роли

---

## Итерация 4: Обработка ошибок

**Цель:** Корректная обработка ошибок API

- [ ] Добавить try-except для вызова LLM
- [ ] Добавить обработку ошибок Telegram API
- [ ] Добавить пользовательское сообщение об ошибке
- [ ] Добавить логирование ошибок через `print()`
- [ ] Протестировать: отключить интернет → бот пишет об ошибке

**Критерий завершения:** Все ошибки обрабатываются, не ломая бота

---

## Итерация 5: Документация

**Цель:** Проект можно запустить по инструкции

- [ ] Создать `README.md` с описанием проекта
- [ ] Добавить инструкцию установки зависимостей
- [ ] Добавить инструкцию настройки .env
- [ ] Добавить инструкцию запуска бота
- [ ] Добавить пример использования
- [ ] Протестировать: новый разработчик запускает по README

**Критерий завершения:** README содержит все необходимые инструкции

---

## Общий критерий успеха

✅ Бот запускается одной командой  
✅ Бот отвечает на вопросы с заданной ролью  
✅ Бот корректно обрабатывает ошибки  
✅ Весь код в одном файле `bot.py`  
✅ Код простой и понятный

